apiVersion: apps/v1
kind: Deployment
metadata:
  namespace: openshift-cluster-machine-approver
  name: machine-approver
  labels:
    app: machine-approver
    machine-approver: "true"
spec:
  strategy:
    type: Recreate
  selector:
    matchLabels:
      app: machine-approver
  template:
    metadata:
      name: machine-approver
      labels:
        app: machine-approver
    spec:
      hostNetwork: true
      serviceAccountName: machine-approver-sa
      containers:
      - name: machine-approver-controller
        image: docker.io/openshift/origin-cluster-machine-approver:v4.0
        imagePullPolicy: IfNotPresent
        command: ["/usr/bin/machine-approver"]
        args:
        - "--config=/var/run/configmaps/config/config.yaml"
        - "-v=2"
        - "--logtostderr"
        resources:
          requests:
            memory: 50Mi
            cpu: 10m
        volumeMounts:
        - mountPath: /var/run/configmaps/config
          name: config
        env:
        - name: KUBERNETES_SERVICE_PORT
          value: "6443"
        - name: KUBERNETES_SERVICE_HOST
          value: "127.0.0.1"
        terminationMessagePolicy: FallbackToLogsOnError
      volumes:
      - name: config
        configMap:
          defaultMode: 440
          name: machine-approver-config
          optional: true
      nodeSelector:
        node-role.kubernetes.io/master: ""
      priorityClassName: "system-cluster-critical"
      tolerations:
      - key: node-role.kubernetes.io/master  # Just tolerate NoSchedule taint on master node. If there are other conditions like disk-pressure etc, let's not schedule the control-plane pods onto that node.
        operator: Exists
        effect: "NoSchedule"
      - key: "node.kubernetes.io/unreachable"
        operator: "Exists"
        effect: "NoExecute"
        tolerationSeconds: 120 # Evict pods within 2 mins.
      - key: "node.kubernetes.io/not-ready"
        operator: "Exists"
        effect: "NoExecute"
        tolerationSeconds: 120 # Evict pods within 2 mins.
